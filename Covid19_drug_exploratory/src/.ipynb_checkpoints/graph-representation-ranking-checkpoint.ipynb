{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SARS-CoV-2 Knowledge Graph "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import time\n",
    "import re\n",
    "import math\n",
    "import random\n",
    "import pickle\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import metrics \n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.autograd import Variable\n",
    "\n",
    "from torch_geometric.data import Data, DataLoader\n",
    "from torch_geometric.utils import add_remaining_self_loops, negative_sampling\n",
    "from torch_geometric.nn import VGAE, GCNConv\n",
    "from torch_geometric.utils import negative_sampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path='data/'\n",
    "exp_id='v0'\n",
    "device_id='cpu' #'cpu' if CPU, device number if GPU\n",
    "embedding_size=128\n",
    "topk=300"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load preprocessed files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "metadata": {},
   "outputs": [],
   "source": [
    "le=pickle.load(open(data_path+'LabelEncoder_'+exp_id+'.pkl', 'rb'))\n",
    "edge_index=pickle.load(open(data_path+'edge_index_'+exp_id+'.pkl','rb'))\n",
    "node_feature_np=pickle.load(open(data_path+'node_feature_'+exp_id+'.pkl','rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "node_feature:  tensor([[-0.7242, -0.4082, -0.4957,  ...,  0.5417, -0.5262, -0.3699],\n",
      "        [-0.7054,  0.2955, -0.4708,  ..., -0.3246, -0.5933, -0.8806],\n",
      "        [-0.7455,  0.5428,  0.4459,  ...,  0.3047,  0.5029,  0.1170],\n",
      "        ...,\n",
      "        [-0.1645,  0.5358,  0.1716,  ...,  0.6800, -0.1641,  0.5851],\n",
      "        [-0.6400, -0.5277,  0.4265,  ...,  0.8151, -0.8159, -0.0602],\n",
      "        [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000]])\n"
     ]
    }
   ],
   "source": [
    "# For tensor representing node\n",
    "node_feature=torch.tensor(node_feature_np, dtype=torch.float)\n",
    "print(\"node_feature: \", node_feature)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 403,   44],\n",
      "        [1287,   44],\n",
      "        [1689,   44],\n",
      "        ...,\n",
      "        [2265,   44],\n",
      "        [2225,   33],\n",
      "        [2211,   54]])\n"
     ]
    }
   ],
   "source": [
    "edge=torch.tensor(edge_index[['node1', 'node2']].values, dtype=torch.long)\n",
    "print(edge)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "metadata": {},
   "outputs": [],
   "source": [
    "# edge_attr_dict maps edge type to the unique numeric identifier\n",
    "edge_attr_dict={'gene-drug':0,'gene-gene':1,'bait-gene':2, 'phenotype-gene':3, 'phenotype-drug':4}\n",
    "edge_index['type']=edge_index['type'].apply(lambda x: edge_attr_dict[x])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "type\n",
       "1    14242\n",
       "4      410\n",
       "3      325\n",
       "2      281\n",
       "0      189\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 215,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "edge_index['type'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0, 0, 0,  ..., 4, 4, 4])\n"
     ]
    }
   ],
   "source": [
    "edge_attr=torch.tensor(edge_index['type'].values,dtype=torch.long)\n",
    "print(edge_attr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preparing a Data object for a graph, including node features, edge information (transposed and contiguous), and edge attributes\n",
    "data = Data(x=node_feature,\n",
    "            edge_index=edge.t().contiguous(),\n",
    "            edge_attr=edge_attr\n",
    "           )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_test_split_edges(data, val_ratio=0.05, test_ratio=0.1):\n",
    "    r\"\"\"Splits the edges of a :obj:`torch_geometric.data.Data` object\n",
    "    into positive and negative train/val/test edges, and adds attributes of\n",
    "    `train_pos_edge_index`, `train_neg_adj_mask`, `val_pos_edge_index`,\n",
    "    `val_neg_edge_index`, `test_pos_edge_index`, and `test_neg_edge_index`\n",
    "    to :attr:`data`.\n",
    "\n",
    "    Args:\n",
    "        data (Data): The data object.\n",
    "        val_ratio (float, optional): The ratio of positive validation\n",
    "            edges. (default: :obj:`0.05`)\n",
    "        test_ratio (float, optional): The ratio of positive test\n",
    "            edges. (default: :obj:`0.1`)\n",
    "\n",
    "    :rtype: :class:`torch_geometric.data.Data`\n",
    "    \"\"\"\n",
    "\n",
    "    assert 'batch' not in data  # No batch-mode.\n",
    "\n",
    "    num_nodes = data.num_nodes\n",
    "    row, col = data.edge_index\n",
    "    #data.edge_index = None\n",
    "    attr = data.edge_attr\n",
    "\n",
    "    # Return upper triangular portion.\n",
    "    #mask = row < col\n",
    "    #row, col = row[mask], col[mask]\n",
    "\n",
    "    n_v = int(math.floor(val_ratio * row.size(0)))\n",
    "    n_t = int(math.floor(test_ratio * row.size(0)))\n",
    "\n",
    "    # Positive edges.\n",
    "    perm = torch.randperm(row.size(0))\n",
    "    row, col = row[perm], col[perm]\n",
    "    attr=attr[perm]\n",
    "\n",
    "    r, c = row[:n_v], col[:n_v]\n",
    "    data.val_pos_edge_index = torch.stack([r, c], dim=0)\n",
    "    data.val_pos_edge_attr = attr[:n_v]\n",
    "    \n",
    "    r, c = row[n_v:n_v + n_t], col[n_v:n_v + n_t]\n",
    "    data.test_pos_edge_index = torch.stack([r, c], dim=0)\n",
    "    data.test_post_edge_attr = attr[n_v:n_v + n_t]\n",
    "\n",
    "    r, c = row[n_v + n_t:], col[n_v + n_t:]\n",
    "    data.train_pos_edge_index = torch.stack([r, c], dim=0)\n",
    "    data.train_pos_edge_attr = attr[n_v+n_t:]\n",
    "\n",
    "    # Negative edges.\n",
    "    neg_adj_mask = torch.ones(num_nodes, num_nodes, dtype=torch.uint8)\n",
    "    neg_adj_mask = neg_adj_mask.triu(diagonal=1).to(torch.bool)\n",
    "    neg_adj_mask[row, col] = 0\n",
    "\n",
    "    neg_row, neg_col = neg_adj_mask.nonzero().t()\n",
    "    perm = random.sample(range(neg_row.size(0)),\n",
    "                         min(n_v + n_t, neg_row.size(0)))\n",
    "    perm = torch.tensor(perm)\n",
    "    perm = perm.to(torch.long)\n",
    "    neg_row, neg_col = neg_row[perm], neg_col[perm]\n",
    "\n",
    "    neg_adj_mask[neg_row, neg_col] = 0\n",
    "    data.train_neg_adj_mask = neg_adj_mask\n",
    "\n",
    "    row, col = neg_row[:n_v], neg_col[:n_v]\n",
    "    data.val_neg_edge_index = torch.stack([row, col], dim=0)\n",
    "\n",
    "    row, col = neg_row[n_v:n_v + n_t], neg_col[n_v:n_v + n_t]\n",
    "    data.test_neg_edge_index = torch.stack([row, col], dim=0)\n",
    "\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "metadata": {},
   "outputs": [],
   "source": [
    "device=torch.device(device_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_split=train_test_split_edges(data)\n",
    "x,train_pos_edge_index,train_pos_edge_attr = data_split.x.to(device), data_split.train_pos_edge_index.to(device), data_split.train_pos_edge_attr.to(device)\n",
    "train_pos_edge_index, train_pos_edge_attr=add_remaining_self_loops(train_pos_edge_index,train_pos_edge_attr)\n",
    "x,train_pos_edge_index,train_pos_edge_attr = Variable(x),Variable(train_pos_edge_index),Variable(train_pos_edge_attr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Learning models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define GCN model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Encoder_GCN(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels, isClassificationTask=False):\n",
    "        super(Encoder_GCN, self).__init__()\n",
    "        self.isClassificationTask=isClassificationTask\n",
    "        self._gene_drug=  GCNConv(in_channels, 2*out_channels)\n",
    "        self._gene_gene = GCNConv(in_channels, 2*out_channels)\n",
    "        self._bait_gene = GCNConv(in_channels, 2*out_channels)\n",
    "        self._gene_phenotype = GCNConv(in_channels, 2*out_channels)\n",
    "        self._drug_phenotype = GCNConv(in_channels, 2*out_channels)\n",
    "\n",
    "        self.bn = nn.BatchNorm1d(5*2*out_channels)\n",
    "        #variational encoder\n",
    "        self._mu = GCNConv(5*2*out_channels, out_channels)\n",
    "        self._logvar = GCNConv(5*2*out_channels, out_channels)\n",
    "\n",
    "    def forward(self,x,edge_index,edge_attr):\n",
    "        \n",
    "        x = F.dropout(x, training=self.training)\n",
    "\n",
    "        # Extract subgraphs based on edge attributes\n",
    "        edge_indices = []\n",
    "        for attr_value in range(5):\n",
    "            indices = (edge_attr == attr_value).nonzero().reshape(1, -1)[0]\n",
    "            edge_indices.append(edge_index[:, indices])\n",
    "        \n",
    "        edge_index_gene_drug, edge_index_gene_gene, edge_index_bait_gene, edge_index_gene_phenotype, edge_index_drug_phenotype = edge_indices\n",
    "\n",
    "        # gcn -> relu -> dropout\n",
    "        x_gene_drug = F.dropout(F.relu(self._gene_drug(x, edge_index_gene_drug)), p=0.5, training=self.training)\n",
    "        x_gene_gene = F.dropout(F.relu(self._gene_gene(x, edge_index_gene_gene)), p=0.5, training=self.training)\n",
    "        x_bait_gene = F.dropout(F.relu(self._bait_gene(x, edge_index_bait_gene)), p=0.1, training=self.training)\n",
    "        x_gene_phenotype = F.dropout(F.relu(self._gene_phenotype(x, edge_index_gene_phenotype)), training=self.training)\n",
    "        x_drug_phenotype = F.dropout(F.relu(self._drug_phenotype(x, edge_index_drug_phenotype)), training=self.training)\n",
    "\n",
    "        # concat\n",
    "        batch_input = torch.cat([x_gene_drug, x_gene_gene, x_bait_gene, x_gene_phenotype, x_drug_phenotype], dim=1)\n",
    "\n",
    "        # batch norm\n",
    "        x = self.bn(batch_input)\n",
    "\n",
    "        return self._mu(x, edge_index), self._logvar(x, edge_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "VGAE(\n",
      "  (encoder): Encoder_GCN(\n",
      "    (_gene_drug): GCNConv(400, 256)\n",
      "    (_gene_gene): GCNConv(400, 256)\n",
      "    (_bait_gene): GCNConv(400, 256)\n",
      "    (_gene_phenotype): GCNConv(400, 256)\n",
      "    (_drug_phenotype): GCNConv(400, 256)\n",
      "    (bn): BatchNorm1d(1280, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (_mu): GCNConv(1280, 128)\n",
      "    (_logvar): GCNConv(1280, 128)\n",
      "  )\n",
      "  (decoder): InnerProductDecoder()\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "model = VGAE(Encoder_GCN(node_feature.shape[1], embedding_size)).to(device)\n",
    "optimizer=torch.optim.Adam(model.parameters(), lr=0.01)\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train():\n",
    "    model.train()\n",
    "    optimizer.zero_grad()\n",
    "    z = model.encode(x, train_pos_edge_index, train_pos_edge_attr)\n",
    "    loss = model.recon_loss(z, train_pos_edge_index)\n",
    "    loss = loss + (1 / data.num_nodes) * model.kl_loss()\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    print(loss.item())\n",
    "    \n",
    "def test(pos_edge_index, neg_edge_index):\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        z=model.encode(x, train_pos_edge_index,train_pos_edge_attr)\n",
    "    return model.test(z, pos_edge_index, neg_edge_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.8260458753926281, 0.7778310666373031)"
      ]
     },
     "execution_count": 224,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#DRKG's accuracy for comparison\n",
    "model.test(x,data_split.test_pos_edge_index, data_split.test_neg_edge_index )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "30.776477813720703\n",
      "Epoch: 001, AUC: 0.6098, AP: 0.5623\n",
      "4225.87158203125\n",
      "Epoch: 002, AUC: 0.5654, AP: 0.5352\n",
      "1297.2353515625\n",
      "Epoch: 003, AUC: 0.5610, AP: 0.5326\n",
      "1541.6563720703125\n",
      "Epoch: 004, AUC: 0.5655, AP: 0.5352\n",
      "1304.3856201171875\n",
      "Epoch: 005, AUC: 0.5873, AP: 0.5481\n",
      "2693.078857421875\n",
      "Epoch: 006, AUC: 0.6041, AP: 0.5584\n",
      "1544.1636962890625\n",
      "Epoch: 007, AUC: 0.6314, AP: 0.5760\n",
      "3082.4345703125\n",
      "Epoch: 008, AUC: 0.6436, AP: 0.5842\n",
      "938.4722290039062\n",
      "Epoch: 009, AUC: 0.6571, AP: 0.5936\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(1, 10):\n",
    "    train()\n",
    "    auc, ap = test(data_split.test_pos_edge_index, data_split.test_neg_edge_index)\n",
    "    print('Epoch: {:03d}, AUC: {:.4f}, AP: {:.4f}'.format(epoch, auc, ap))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Node embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.eval()\n",
    "z=model.encode(x, data.edge_index.to(device), data.edge_attr.to(device))\n",
    "z_np = z.squeeze().detach().cpu().numpy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Save the new embedding "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "metadata": {},
   "outputs": [],
   "source": [
    "pickle.dump(z_np, open(data_path+'node_embedding_'+exp_id+'.pkl', 'wb'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Save the torch model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model.state_dict(), data_path+'VAE_encoders_'+exp_id+'.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "VGAE(\n",
       "  (encoder): Encoder_GCN(\n",
       "    (_gene_drug): GCNConv(400, 256)\n",
       "    (_gene_gene): GCNConv(400, 256)\n",
       "    (_bait_gene): GCNConv(400, 256)\n",
       "    (_gene_phenotype): GCNConv(400, 256)\n",
       "    (_drug_phenotype): GCNConv(400, 256)\n",
       "    (bn): BatchNorm1d(1280, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (_mu): GCNConv(1280, 128)\n",
       "    (_logvar): GCNConv(1280, 128)\n",
       "  )\n",
       "  (decoder): InnerProductDecoder()\n",
       ")"
      ]
     },
     "execution_count": 229,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.load_state_dict(torch.load(data_path+'VAE_encoders_'+exp_id+'.pkl'))\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ranking model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "metadata": {},
   "outputs": [],
   "source": [
    "types=np.array([classtype.split('_')[0] for classtype in le.classes_ ])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load drugs under clinical trial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "metadata": {},
   "outputs": [],
   "source": [
    "#label\n",
    "trials=pd.read_excel(data_path+'literature-mining/All_trails_5_24.xlsx',header=1,index_col=0)\n",
    "trials_drug=set([drug.strip().upper() for lst in trials.loc[trials['study_category'].apply(lambda x: 'drug' in x.lower()),'intervention'].apply(lambda x: re.split(r'[+|/|,]',x.replace(' vs. ', '/').replace(' vs ', '/').replace(' or ', '/').replace(' with and without ', '/').replace(' /wo ', '/').replace(' /w ', '/').replace(' and ', '/').replace(' - ', '/').replace(' (', '/').replace(') ', '/'))).values for drug in lst])\n",
    "drug_labels=[1 if drug.split('_')[1] in trials_drug else 0 for drug in le.classes_[types=='drug'] ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "metadata": {},
   "outputs": [],
   "source": [
    "indices = np.arange(len(drug_labels))\n",
    "X_train, X_test, y_train, y_test, indices_train, indices_test = train_test_split(z_np[types=='drug'], drug_labels, indices, test_size=0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Variable wrapping for torch.tensor\n",
    "_X_train, _y_train=Variable(torch.tensor(X_train,dtype=torch.float).to(device)), Variable(torch.tensor(y_train,dtype=torch.float).to(device))\n",
    "_X_test, _y_test=Variable(torch.tensor(X_test,dtype=torch.float).to(device)), Variable(torch.tensor(y_test,dtype=torch.float).to(device))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "NN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Classifier(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Classifier, self).__init__() \n",
    "        self.fc1=nn.Linear(128,128)\n",
    "        self.fc2=nn.Linear(128,1)\n",
    "        self.bn=nn.BatchNorm1d(128)\n",
    "    def forward(self, x):\n",
    "        residual = x\n",
    "        out = F.dropout(F.relu(self.fc1(x)))\n",
    "        out = self.bn(out)\n",
    "        out += residual\n",
    "        return self.fc2(x)        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "BPR Loss Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import BatchSampler, WeightedRandomSampler\n",
    "class BPRLoss(nn.Module):\n",
    "    def __init__(self, num_neg_samples):\n",
    "        super(BPRLoss, self).__init__()\n",
    "        self.num_neg_samples=num_neg_samples\n",
    "    \n",
    "    def forward(self, output, label):\n",
    "        positive_output=output[label==1]\n",
    "        negative_output=output[label!=1]\n",
    "\n",
    "        log_prob = F.logsigmoid(positive_output.view(-1,1) - negative_output).mean()\n",
    "\n",
    "        return -log_prob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf=Classifier().to(device)\n",
    "optimizer=torch.optim.Adam(clf.parameters())\n",
    "criterion=BPRLoss(num_neg_samples=15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 238,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training loss 1.3339946269989014\n",
      "test loss 0.5207222104072571\n",
      "training loss 1.0608125925064087\n",
      "test loss 0.5801140069961548\n",
      "training loss 0.9250597357749939\n",
      "test loss 0.8643887042999268\n",
      "training loss 1.0317251682281494\n",
      "test loss 0.8753237128257751\n",
      "training loss 1.0192252397537231\n",
      "test loss 0.7023117542266846\n",
      "training loss 0.9109266400337219\n",
      "test loss 0.5697870850563049\n",
      "training loss 0.8488369584083557\n",
      "test loss 0.5141294002532959\n",
      "training loss 0.8488251566886902\n",
      "test loss 0.49606671929359436\n",
      "training loss 0.8623873591423035\n",
      "test loss 0.4897958040237427\n",
      "training loss 0.8599364757537842\n",
      "test loss 0.48686501383781433\n",
      "training loss 0.8348497152328491\n",
      "test loss 0.48861661553382874\n",
      "training loss 0.7930968403816223\n",
      "test loss 0.502312421798706\n",
      "training loss 0.7478501796722412\n",
      "test loss 0.5382651686668396\n",
      "training loss 0.7162315845489502\n",
      "test loss 0.5988163948059082\n",
      "training loss 0.709517240524292\n",
      "test loss 0.6545520424842834\n",
      "training loss 0.7136891484260559\n",
      "test loss 0.6603466868400574\n",
      "training loss 0.6997525691986084\n",
      "test loss 0.6152487397193909\n",
      "training loss 0.6660490036010742\n",
      "test loss 0.5569425225257874\n",
      "training loss 0.6353330612182617\n",
      "test loss 0.5141671299934387\n",
      "training loss 0.6207406520843506\n",
      "test loss 0.4910983443260193\n",
      "training loss 0.6160561442375183\n",
      "test loss 0.48175594210624695\n",
      "training loss 0.6100027561187744\n",
      "test loss 0.4816175103187561\n",
      "training loss 0.5965954661369324\n",
      "test loss 0.4903223216533661\n",
      "training loss 0.5767126679420471\n",
      "test loss 0.5104929208755493\n",
      "training loss 0.5562548637390137\n",
      "test loss 0.5435795187950134\n",
      "training loss 0.5423444509506226\n",
      "test loss 0.5820839405059814\n",
      "training loss 0.5368223190307617\n",
      "test loss 0.6071096658706665\n",
      "training loss 0.5323694944381714\n",
      "test loss 0.6040023565292358\n",
      "training loss 0.5212066769599915\n",
      "test loss 0.578157365322113\n",
      "training loss 0.5057593584060669\n",
      "test loss 0.5472094416618347\n"
     ]
    }
   ],
   "source": [
    "best_auprc=0\n",
    "for epoch in range(30):\n",
    "    clf.train()\n",
    "    optimizer.zero_grad()\n",
    "    out = clf(_X_train)\n",
    "    loss=criterion(out.squeeze(), _y_train)\n",
    "    loss.backward()\n",
    "    optimizer.step()   \n",
    "    print('training loss',loss.item())\n",
    "\n",
    "    clf.eval()\n",
    "    print('test loss', criterion(clf(_X_test).squeeze(), _y_test).item())\n",
    "    prob=torch.sigmoid(clf(_X_test)).cpu().detach().numpy().squeeze()\n",
    "    auprc=metrics.average_precision_score(y_test,prob)\n",
    "    if auprc>best_auprc:\n",
    "        best_auproc=auprc\n",
    "        torch.save(clf, data_path+'nn_clf-temp.pt')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 239,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 239,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.load_state_dict(torch.load(data_path+'nn_clf-temp.pt').state_dict())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AUROC 0.7142857142857143\n",
      "AUPRC 0.6692628205128205\n"
     ]
    }
   ],
   "source": [
    "#Compute AUC\n",
    "clf.eval()\n",
    "\n",
    "prob=torch.sigmoid(clf(_X_test)).cpu().detach().numpy().squeeze()\n",
    "print(\"AUROC\", metrics.roc_auc_score(y_test,prob))\n",
    "print(\"AUPRC\", metrics.average_precision_score(y_test,prob))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 241,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([40, 27, 29, 45, 21, 12, 15, 41, 22, 36, 25,  7, 19, 33, 38,  8, 24,\n",
       "       10, 17, 39, 31,  6, 32,  3,  9, 28,  5, 37, 26, 16, 18, 46,  1, 44,\n",
       "       35, 30, 14, 43, 23, 11, 42, 20,  4,  2, 34, 13,  0], dtype=int64)"
      ]
     },
     "execution_count": 241,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "z_np[types=='drug']\n",
    "res_tensor = -clf(torch.from_numpy(z_np[types=='drug']))\n",
    "sorted_picks = np.argsort(res_tensor.squeeze().detach().numpy())\n",
    "sorted_picks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Save the high-ranked drugs into csv file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "topk_drugs=pd.DataFrame([(rank, drug.split('_')[1]) for rank,drug in enumerate(le.inverse_transform((types=='drug').nonzero()[0][sorted_picks])[:topk+1])], columns=['rank', 'drug'])\n",
    "topk_drugs['under_trials']=topk_drugs['drug'].isin(trials_drug).astype(int)\n",
    "topk_drugs['is_used_in_training']=topk_drugs['drug'].isin(np.array([drug.split('_')[1] for drug in le.classes_[types=='drug']])[indices_train]).astype(int)\n",
    "topk_drugs.to_csv('top300_drugs.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
